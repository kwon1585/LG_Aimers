{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273b75f6-25fa-4f9c-8c9d-fa33a985f2dd",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c415d9d-1111-46ed-bc2d-849c75ab962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f9c1c-39bc-42e7-a00d-3062d11b4f1e",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee76c413-001b-475e-9d1c-6662d25d2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_df = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'PRODUCT_CODE'])\n",
    "test_line = test_df['LINE']\n",
    "test_df = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'LINE', 'PRODUCT_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05cac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f1e6b-97f4-4f90-b3ce-0513b7196db6",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c72765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T010305':\n",
    "    idx1 = idx\n",
    "    break\n",
    "data_line_1 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)\n",
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T010306':\n",
    "    idx2 = idx\n",
    "    break\n",
    "data_line_2 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)\n",
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T050304':\n",
    "    idx3 = idx\n",
    "    break\n",
    "data_line_3 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)\n",
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T050307':\n",
    "    idx4 = idx\n",
    "    break\n",
    "data_line_4 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)\n",
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T100304':\n",
    "    idx5 = idx\n",
    "    break\n",
    "data_line_5 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)\n",
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T100306':\n",
    "    idx6 = idx\n",
    "    break\n",
    "data_line_6 = pd.DataFrame(train_df.loc[idx]).transpose()\n",
    "train_df = train_df.drop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b73b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in train_df.iterrows():\n",
    "  if data['LINE'] == 'T010305': \n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_1 = pd.concat([data_line_1, data_tmp])\n",
    "  elif data['LINE'] == 'T010306': \n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_2 = pd.concat([data_line_2, data_tmp])\n",
    "  elif data['LINE'] == 'T050304': \n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_3 = pd.concat([data_line_3, data_tmp])\n",
    "  elif data['LINE'] == 'T050307':   \n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_4 = pd.concat([data_line_4, data_tmp])\n",
    "  elif data['LINE'] == 'T100304': \n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_5 = pd.concat([data_line_5, data_tmp])\n",
    "  else :\n",
    "    data_tmp = pd.DataFrame(data).transpose()\n",
    "    data_line_6 = pd.concat([data_line_6, data_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42fcd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_line_1 = data_line_1.dropna(axis=1)\n",
    "data_line_2 = data_line_2.dropna(axis=1)\n",
    "data_line_3 = data_line_3.dropna(axis=1)\n",
    "data_line_4 = data_line_4.dropna(axis=1)\n",
    "data_line_5 = data_line_5.dropna(axis=1)\n",
    "data_line_6 = data_line_6.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa9fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_1.std())\n",
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_2.std())\n",
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_3.std())\n",
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_4.std())\n",
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:6: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_5.std())\n",
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_61392/2627727357.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  data_std.append(data_line_6.std())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m: \u001b[39mdel\u001b[39;00m data_line_3[idx]\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m idx, x \u001b[39min\u001b[39;00m data_std[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39miteritems():\n\u001b[0;32m---> 16\u001b[0m   \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m: \u001b[39mdel\u001b[39;00m data_line_4[idx]\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m idx, x \u001b[39min\u001b[39;00m data_std[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39miteritems():\n\u001b[1;32m     18\u001b[0m   \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m x \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m: \u001b[39mdel\u001b[39;00m data_line_5[idx]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:4049\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deleted:\n\u001b[1;32m   4045\u001b[0m     \u001b[39m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[1;32m   4046\u001b[0m     \u001b[39m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[1;32m   4047\u001b[0m     \u001b[39m# exception:\u001b[39;00m\n\u001b[1;32m   4048\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mget_loc(key)\n\u001b[0;32m-> 4049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49midelete(loc)\n\u001b[1;32m   4051\u001b[0m \u001b[39m# delete from the caches\u001b[39;00m\n\u001b[1;32m   4052\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py:1317\u001b[0m, in \u001b[0;36mBlockManager.idelete\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1314\u001b[0m is_deleted[indexer] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m taker \u001b[39m=\u001b[39m (\u001b[39m~\u001b[39mis_deleted)\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1317\u001b[0m nbs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_take_blocks_ax0(taker, only_slice\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1318\u001b[0m new_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems[\u001b[39m~\u001b[39mis_deleted]\n\u001b[1;32m   1319\u001b[0m axes \u001b[39m=\u001b[39m [new_columns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[\u001b[39m1\u001b[39m]]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py:824\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[39m# GH#32779 to avoid the performance penalty of copying,\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m#  we may try to only slice\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     taker \u001b[39m=\u001b[39m blklocs[mgr_locs\u001b[39m.\u001b[39mindexer]\n\u001b[0;32m--> 824\u001b[0m     max_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(mgr_locs), taker\u001b[39m.\u001b[39;49mmax() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m only_slice:\n\u001b[1;32m    826\u001b[0m         taker \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_indices_to_slice(taker, max_len)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:38\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     32\u001b[0m     _complex_to_float\u001b[39m.\u001b[39mupdate({\n\u001b[1;32m     33\u001b[0m         nt\u001b[39m.\u001b[39mdtype(nt\u001b[39m.\u001b[39mclongdouble) : nt\u001b[39m.\u001b[39mdtype(nt\u001b[39m.\u001b[39mlongdouble),\n\u001b[1;32m     34\u001b[0m     })\n\u001b[1;32m     36\u001b[0m \u001b[39m# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# small reductions\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[39mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_std = []\n",
    "data_std.append(data_line_1.std())\n",
    "data_std.append(data_line_2.std())\n",
    "data_std.append(data_line_3.std())\n",
    "data_std.append(data_line_4.std())\n",
    "data_std.append(data_line_5.std())\n",
    "data_std.append(data_line_6.std())\n",
    "\n",
    "for idx, x in data_std[0].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_1[idx]\n",
    "for idx, x in data_std[1].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_2[idx]\n",
    "for idx, x in data_std[2].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_3[idx]\n",
    "for idx, x in data_std[3].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_4[idx]\n",
    "for idx, x in data_std[4].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_5[idx]\n",
    "for idx, x in data_std[5].iteritems():\n",
    "  if x == 0 or x >= 10000: del data_line_6[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index_1 = []\n",
    "data_index_2 = []\n",
    "data_index_3 = []\n",
    "data_index_4 = []\n",
    "data_index_5 = []\n",
    "data_index_6 = []\n",
    "\n",
    "for i in range(len(data_line_1)):\n",
    "  for idx, data in data_line_1.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_1.append(idx)\n",
    "\n",
    "for i in range(len(data_line_2)):\n",
    "  for idx, data in data_line_2.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_2.append(idx)\n",
    "\n",
    "for i in range(len(data_line_3)):\n",
    "  for idx, data in data_line_3.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_3.append(idx)\n",
    "\n",
    "for i in range(len(data_line_4)):\n",
    "  for idx, data in data_line_4.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_4.append(idx)\n",
    "\n",
    "for i in range(len(data_line_5)):\n",
    "  for idx, data in data_line_5.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_5.append(idx)\n",
    "\n",
    "for i in range(len(data_line_6)):\n",
    "  for idx, data in data_line_6.iloc[i].iteritems():\n",
    "    if idx[0] == 'X': data_index_6.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_1)):\n",
    "#   for idx, data in data_line_1.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_1[idx]\n",
    "#       elif i == (len(data_line_1) - 1) : data_index_1.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_2)):\n",
    "#   for idx, data in data_line_2.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_2[idx]\n",
    "#       elif i == (len(data_line_2) - 1) : data_index_2.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_3)):\n",
    "#   for idx, data in data_line_3.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_3[idx]\n",
    "#       elif i == (len(data_line_3) - 1) : data_index_3.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_4)):\n",
    "#   for idx, data in data_line_4.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_4[idx]\n",
    "#       elif i == (len(data_line_4) - 1) : data_index_4.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_5)):\n",
    "#   for idx, data in data_line_5.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_5[idx]\n",
    "#       elif i == (len(data_line_5) - 1) : data_index_5.append(idx)\n",
    "\n",
    "# for i in range(len(data_line_6)):\n",
    "#   for idx, data in data_line_6.iloc[i].iteritems():\n",
    "#     if idx[0] == 'X':\n",
    "#       if data == 'NaN' :\n",
    "#         del data_line_6[idx]\n",
    "#       elif i == (len(data_line_6) - 1) : data_index_6.append(idx)\n",
    "\n",
    "data_index = []\n",
    "data_index.append(data_index_1)\n",
    "data_index.append(data_index_2)\n",
    "data_index.append(data_index_3)\n",
    "data_index.append(data_index_4)\n",
    "data_index.append(data_index_5)\n",
    "data_index.append(data_index_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26170d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target_1 = data_line_1['Y_Quality'].values.tolist()\n",
    "data_target_2 = data_line_2['Y_Quality'].values.tolist()\n",
    "data_target_3 = data_line_3['Y_Quality'].values.tolist()\n",
    "data_target_4 = data_line_4['Y_Quality'].values.tolist()\n",
    "data_target_5 = data_line_5['Y_Quality'].values.tolist()\n",
    "data_target_6 = data_line_6['Y_Quality'].values.tolist()\n",
    "\n",
    "data_line_1 = data_line_1.drop(columns=['Y_Quality', 'LINE'])\n",
    "data_line_2 = data_line_2.drop(columns=['Y_Quality', 'LINE'])\n",
    "data_line_3 = data_line_3.drop(columns=['Y_Quality', 'LINE'])\n",
    "data_line_4 = data_line_4.drop(columns=['Y_Quality', 'LINE'])\n",
    "data_line_5 = data_line_5.drop(columns=['Y_Quality', 'LINE'])\n",
    "data_line_6 = data_line_6.drop(columns=['Y_Quality', 'LINE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = []\n",
    "data_mean.append(data_line_1.mean())\n",
    "data_mean.append(data_line_2.mean())\n",
    "data_mean.append(data_line_3.mean())\n",
    "data_mean.append(data_line_4.mean())\n",
    "data_mean.append(data_line_5.mean())\n",
    "data_mean.append(data_line_6.mean())\n",
    "\n",
    "data_std = []\n",
    "data_std.append(data_line_1.std())\n",
    "data_std.append(data_line_2.std())\n",
    "data_std.append(data_line_3.std())\n",
    "data_std.append(data_line_4.std())\n",
    "data_std.append(data_line_5.std())\n",
    "data_std.append(data_line_6.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_line_1 = (data_line_1 - data_mean[0]) / data_std[0]\n",
    "data_line_2 = (data_line_2 - data_mean[1]) / data_std[1]\n",
    "data_line_3 = (data_line_3 - data_mean[2]) / data_std[2]\n",
    "data_line_4 = (data_line_4 - data_mean[3]) / data_std[3]\n",
    "data_line_5 = (data_line_5 - data_mean[4]) / data_std[4]\n",
    "data_line_6 = (data_line_6 - data_mean[5]) / data_std[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695 697 745 1186 169 535\n"
     ]
    }
   ],
   "source": [
    "len_line_1 = len(data_line_1.columns)\n",
    "len_line_2 = len(data_line_2.columns)\n",
    "len_line_3 = len(data_line_3.columns)\n",
    "len_line_4 = len(data_line_4.columns)\n",
    "len_line_5 = len(data_line_5.columns)\n",
    "len_line_6 = len(data_line_6.columns)\n",
    "\n",
    "print(len_line_1, len_line_2, len_line_3, len_line_4, len_line_5, len_line_6)\n",
    "\n",
    "data_line_1 = data_line_1.values.tolist()\n",
    "data_line_2 = data_line_2.values.tolist()\n",
    "data_line_3 = data_line_3.values.tolist()\n",
    "data_line_4 = data_line_4.values.tolist()\n",
    "data_line_5 = data_line_5.values.tolist()\n",
    "data_line_6 = data_line_6.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(lst):\n",
    "  for i in range(len(lst)):\n",
    "    lst[i] = [float(x) for x in lst[i]]\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_line_1 = to_float(data_line_1)\n",
    "data_line_2 = to_float(data_line_2)\n",
    "data_line_3 = to_float(data_line_3)\n",
    "data_line_4 = to_float(data_line_4)\n",
    "data_line_5 = to_float(data_line_5)\n",
    "data_line_6 = to_float(data_line_6)\n",
    "\n",
    "data_target_1 = [float((x - 0.53089627)/0.00739057) for x in data_target_1]\n",
    "data_target_2 = [float((x - 0.53089627)/0.00739057) for x in data_target_2]\n",
    "data_target_3 = [float((x - 0.53089627)/0.00739057) for x in data_target_3]\n",
    "data_target_4 = [float((x - 0.53089627)/0.00739057) for x in data_target_4]\n",
    "data_target_5 = [float((x - 0.53089627)/0.00739057) for x in data_target_5]\n",
    "data_target_6 = [float((x - 0.53089627)/0.00739057) for x in data_target_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_line_1 = torch.tensor(data_line_1)\n",
    "data_line_2 = torch.tensor(data_line_2)\n",
    "data_line_3 = torch.tensor(data_line_3)\n",
    "data_line_4 = torch.tensor(data_line_4)\n",
    "data_line_5 = torch.tensor(data_line_5)\n",
    "data_line_6 = torch.tensor(data_line_6)\n",
    "\n",
    "data_target_1 = torch.tensor(data_target_1)\n",
    "data_target_2 = torch.tensor(data_target_2)\n",
    "data_target_3 = torch.tensor(data_target_3)\n",
    "data_target_4 = torch.tensor(data_target_4)\n",
    "data_target_5 = torch.tensor(data_target_5)\n",
    "data_target_6 = torch.tensor(data_target_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec6b34-1e64-4d20-afdd-e96f4f77fa31",
   "metadata": {},
   "source": [
    "## Classification Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Idea1(nn.Module):\n",
    "    def __init__(self, len_line):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(len_line, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca77bc-154c-4cb3-9251-3fe45d671416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Idea1(len_line_1)\n",
    "model_2 = Idea1(len_line_2)\n",
    "model_3 = Idea1(len_line_3)\n",
    "model_4 = Idea1(len_line_4)\n",
    "model_5 = Idea1(len_line_5)\n",
    "model_6 = Idea1(len_line_6)\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=1.0e-3)\n",
    "optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=1.0e-3)\n",
    "optimizer_3 = torch.optim.Adam(model_3.parameters(), lr=1.0e-3)\n",
    "optimizer_4 = torch.optim.Adam(model_4.parameters(), lr=1.0e-3)\n",
    "optimizer_5 = torch.optim.Adam(model_5.parameters(), lr=1.0e-3)\n",
    "optimizer_6 = torch.optim.Adam(model_6.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdc15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:9: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_1[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04898557427263468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:21: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_2[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05100828741576146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:33: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_3[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04786486260132965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:45: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_4[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09403331115795867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:57: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_5[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012737696936684863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/5y70dmpj6gz7vm0lv4mwhnzc0000gn/T/ipykernel_43224/230348249.py:69: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data_target_6[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015031250675224064\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "loss_avg = 0\n",
    "model_1.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_1):\n",
    "        optimizer_1.zero_grad()\n",
    "        out = model_1(data)\n",
    "        loss = F.mse_loss(out, data_target_1[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "model_2.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_2):\n",
    "        optimizer_2.zero_grad()\n",
    "        out = model_2(data)\n",
    "        loss = F.mse_loss(out, data_target_2[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_2.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "loss_avg = 0\n",
    "model_3.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_3):\n",
    "        optimizer_3.zero_grad()\n",
    "        out = model_3(data)\n",
    "        loss = F.mse_loss(out, data_target_3[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_3.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "loss_avg = 0\n",
    "model_4.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_4):\n",
    "        optimizer_4.zero_grad()\n",
    "        out = model_4(data)\n",
    "        loss = F.mse_loss(out, data_target_4[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_4.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "loss_avg = 0\n",
    "model_5.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_5):\n",
    "        optimizer_5.zero_grad()\n",
    "        out = model_5(data)\n",
    "        loss = F.mse_loss(out, data_target_5[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_5.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "loss_avg = 0\n",
    "model_6.train()\n",
    "for epoch in range(epochs):\n",
    "    for idx, data in enumerate(data_line_6):\n",
    "        optimizer_6.zero_grad()\n",
    "        out = model_6(data)\n",
    "        loss = F.mse_loss(out, data_target_6[idx])\n",
    "        loss_avg += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_6.step()\n",
    "    print(loss_avg /((idx+1)))\n",
    "    loss_avg = 0\n",
    "\n",
    "model_list = []\n",
    "model_list.append(model_1)\n",
    "model_list.append(model_2)\n",
    "model_list.append(model_3)\n",
    "model_list.append(model_4)\n",
    "model_list.append(model_5)\n",
    "model_list.append(model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddaa38-bd6e-47d2-82d3-c000f188886a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fd3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_line(line):\n",
    "  if line == 'T010305': return 0\n",
    "  elif line == 'T010306': return 1\n",
    "  elif line == 'T050304': return 2\n",
    "  elif line == 'T050307': return 3\n",
    "  elif line == 'T100304': return 4\n",
    "  else : return 5\n",
    "\n",
    "def test_data_converter(data, data_index, data_mean, data_std):\n",
    "  head = 0\n",
    "  rtn = []\n",
    "  max = len(data_index)\n",
    "  for num, val in enumerate(data.index):\n",
    "    if data_index[head] == val:\n",
    "      if data[num] == 'NaN' :\n",
    "        rtn.append(data_mean[head])\n",
    "      else :\n",
    "        rtn.append((data[num] - data_mean[head]) / data_std[head])\n",
    "      head+=1\n",
    "    if head == max : break\n",
    "  return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bdb9b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 -1.3535526990890503\n",
      "36 3232519684096.0\n",
      "62 3232519684096.0\n",
      "63 3232519684096.0\n",
      "130 3232519684096.0\n",
      "131 3232519684096.0\n",
      "132 3238244646912.0\n",
      "248 3239665729536.0\n",
      "249 3232519684096.0\n",
      "250 3232519684096.0\n",
      "251 3232519684096.0\n",
      "252 3232519684096.0\n",
      "253 3232519684096.0\n",
      "254 3225374162944.0\n",
      "255 3232519684096.0\n",
      "260 3232519684096.0\n",
      "263 3232519684096.0\n",
      "280 3232519684096.0\n",
      "281 3232519684096.0\n",
      "282 3225374162944.0\n",
      "283 3232519684096.0\n",
      "284 3232519684096.0\n",
      "285 3232519684096.0\n",
      "286 3232519684096.0\n",
      "292 3232519684096.0\n",
      "293 3232519684096.0\n",
      "1.2127841711044312\n",
      "0.7900664806365967\n",
      "0.8395056128501892\n",
      "1.1728708744049072\n",
      "0.8986860513687134\n",
      "1.0507025718688965\n",
      "0.9845203161239624\n",
      "1.0880115032196045\n",
      "1.0376360416412354\n",
      "1.093931794166565\n",
      "5.980623245239258\n",
      "-0.2317846119403839\n",
      "1.7626423835754395\n",
      "2.12003493309021\n",
      "4.187373638153076\n",
      "2.2132952213287354\n",
      "1.5754669904708862\n",
      "3.3194427490234375\n",
      "0.9041202068328857\n",
      "-1.0553163290023804\n",
      "-0.9142990112304688\n",
      "-0.7927830219268799\n",
      "1.7605500221252441\n",
      "0.5303436517715454\n",
      "2.5455427169799805\n",
      "2.7514452934265137\n",
      "1.182215929031372\n",
      "0.21350282430648804\n",
      "-0.3713485300540924\n",
      "-0.7256603240966797\n",
      "-0.7583070993423462\n",
      "-1.9290064573287964\n",
      "-0.8644472360610962\n",
      "-1.2724339962005615\n",
      "-1.5465161800384521\n",
      "-1.2089899778366089\n",
      "-1.4870885610580444\n",
      "0.39205828309059143\n",
      "0.38883718848228455\n",
      "-0.752449631690979\n",
      "-0.14691710472106934\n",
      "-1.2572985887527466\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "result = []\n",
    "wrong_line = [0,0,0,0,0,0]\n",
    "\n",
    "for idx, data in test_df.iterrows():\n",
    "  i = find_line(test_line[idx])\n",
    "  test_data = test_data_converter(data, data_index[i], data_mean[i], data_std[i])\n",
    "  test_data = [float(x) for x in test_data]\n",
    "  output = model_list[i](torch.tensor(test_data))\n",
    "  result.append(output.item())\n",
    "  if output.item() >= 6.5 or output.item() <= -4.5 :\n",
    "    wrong_line[i] += 1\n",
    "  if i == 3: print(idx, output.item())\n",
    "\n",
    "for idx, data in enumerate(data_line_4):\n",
    "  out = model_list[3](data)\n",
    "  print(out.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "722804b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 25, 0, 0]\n",
      "[0.03069913387298584, -0.135151207447052, -0.05001655966043472, -1.229386568069458, -0.01848292350769043, -0.2510102391242981, -0.5221839547157288, -0.9315066337585449, -0.891624927520752, 0.2409047782421112, -0.5986147522926331, -0.3331821858882904, 0.7044686675071716, -1.3535526990890503, -0.2911107838153839, 0.18334171175956726, 0.042252689599990845, -0.18587970733642578, 0.2995344400405884, -0.28840041160583496, 0.6668457984924316, -0.21255776286125183, -0.1513080894947052, -0.3048941493034363, -0.060247935354709625, -0.14673028886318207, -0.14203596115112305, -0.05054261535406113, -0.9202780723571777, -0.46153369545936584, -1.1115816831588745, -0.19065922498703003, -0.21981322765350342, -0.25770071148872375, -0.09618422389030457, -1.2123210430145264, 3232519684096.0, 0.8146296739578247, 0.05368522182106972, -0.3397676944732666, 0.05368522182106972, 0.12823054194450378, -0.3590512275695801, -0.7007594108581543, -0.4944819509983063, -0.023958414793014526, -0.16540765762329102, -1.2344788312911987, 0.13306628167629242, -0.6929342150688171, -0.018480271100997925, -1.6449676752090454, -1.608709692955017, -1.770511269569397, -1.9992740154266357, -1.1683367490768433, -0.3138100206851959, -0.5742456912994385, -1.6389175653457642, -1.3421485424041748, -1.473331093788147, -0.8889058828353882, 3232519684096.0, 3232519684096.0, -1.78800368309021, -1.5016114711761475, -1.0365931987762451, 0.09265285730361938, 0.11630236357450485, -0.08609212189912796, -0.08609212189912796, -0.7727787494659424, 0.6429411768913269, -0.08609212189912796, -0.320667028427124, 0.10067396610975266, -0.39447787404060364, -0.07708018273115158, 0.19231395423412323, 2729.223388671875, 0.077340267598629, 0.026275373995304108, 0.33325254917144775, -0.039523784071207047, 0.46553003787994385, 0.49795880913734436, -1.7570343017578125, 0.4738162159919739, -1.2353339195251465, -0.9460826516151428, -0.08609212189912796, 0.13033618032932281, -0.009554460644721985, 0.5219009518623352, -0.48758015036582947, 0.39834028482437134, -0.35838204622268677, -0.0669625923037529, -0.08819504082202911, 0.24285286664962769, -0.26802685856819153, -0.06267787516117096, 0.28559160232543945, 0.21943116188049316, 0.044787608087062836, 0.08633212000131607, -0.08609212189912796, -0.3821509778499603, 0.5914329290390015, 0.836304783821106, -0.4630261957645416, -0.549653172492981, -0.15609481930732727, 0.40490061044692993, 1.4829003810882568, 1.3856019973754883, -0.5476201772689819, -0.2103879451751709, -0.08007368445396423, 0.12557774782180786, -0.7381987571716309, -0.2338409423828125, 0.4095536470413208, 0.40747398138046265, -0.28795579075813293, -0.5460965633392334, 0.2424584925174713, -0.48312631249427795, -0.6362159848213196, 0.36541882157325745, 3232519684096.0, 3232519684096.0, 3238244646912.0, -0.28386953473091125, 0.6398708820343018, 0.5805219411849976, -0.7706232070922852, 0.19171738624572754, -0.08609212189912796, -0.4652804434299469, -0.5038665533065796, -1.0246814489364624, -0.884125828742981, -0.6928473711013794, 0.38646358251571655, 1.0908254384994507, -0.4239993989467621, 0.1738978922367096, -0.4048578441143036, -0.4097658693790436, -0.5804810523986816, 0.3677232563495636, -0.2994767427444458, -0.15118932723999023, -0.784401535987854, 0.8205961585044861, -0.5964604616165161, 0.2730724811553955, 0.6506050825119019, -0.25386562943458557, -0.4196353256702423, 2.1242830753326416, -0.490180104970932, 1.2329970598220825, -0.1471017599105835, 0.1450534164905548, -0.23120945692062378, -0.5847527980804443, -0.6310832500457764, 0.9851862192153931, 1.104309320449829, -0.7066617012023926, 1.0806772708892822, -0.3216046392917633, 0.42720627784729004, -0.33545488119125366, 0.4759741425514221, 1.3828390836715698, -0.3448214530944824, 0.9274786710739136, 0.9764771461486816, -0.1710585355758667, -0.3297964036464691, 1.238412618637085, -0.1475580334663391, -0.06564648449420929, -1.128402829170227, 1.3613691329956055, -1.507659673690796, 1.3840059041976929, -1.4210944175720215, 1.3655979633331299, -1.5953161716461182, 1.0714061260223389, -0.5311018228530884, 1.1824370622634888, 0.5224316120147705, -0.7129590511322021, 0.9590831995010376, -0.42839112877845764, 1.149706482887268, -0.20745381712913513, 0.9226598739624023, -0.25046417117118835, 1.0928046703338623, 1.1931649446487427, -0.46295174956321716, 0.9294350147247314, -0.13844150304794312, 0.976341724395752, -0.2842206060886383, -0.20833316445350647, 1.023817777633667, -0.1978428065776825, 1.5181487798690796, 0.026627421379089355, -0.24237439036369324, 0.7912477850914001, -0.1851075291633606, 0.8460995554924011, 0.014607787132263184, 1.047573208808899, 1.509434461593628, -0.1402592957019806, -0.296353280544281, -0.1393434703350067, 1.2144864797592163, -0.14197483658790588, 0.7006083130836487, -0.36506542563438416, -0.03780737519264221, -0.11337998509407043, 0.15452703833580017, 1.3616372346878052, 0.8910123705863953, -0.002911388874053955, -0.22767424583435059, -0.1382167935371399, 0.82061767578125, -0.3136492371559143, -0.04591885209083557, 0.9396082162857056, -0.3374418318271637, 1.0026240348815918, 0.6690546870231628, 0.652529239654541, 0.36135974526405334, -0.07422646880149841, 3239665729536.0, 3232519684096.0, 3232519684096.0, 3232519684096.0, 3232519684096.0, 3232519684096.0, 3225374162944.0, 3232519684096.0, 0.5660935640335083, 0.38125061988830566, 0.7000170350074768, 0.09876659512519836, 3232519684096.0, -0.34694018959999084, -0.2376890480518341, 3232519684096.0, 0.4935559630393982, -0.7205888032913208, -0.032164424657821655, -0.13022679090499878, -0.1287497580051422, -0.19433242082595825, -0.28340432047843933, 0.31645190715789795, 0.9775660037994385, -0.33149275183677673, -0.3030554950237274, -0.3609645962715149, -0.1700955033302307, 0.7341729402542114, -0.3591276705265045, -0.5892566442489624, 3232519684096.0, 3232519684096.0, 3225374162944.0, 3232519684096.0, 3232519684096.0, 3232519684096.0, 3232519684096.0, -0.042338453233242035, -0.3073355555534363, 0.038899220526218414, -0.25793570280075073, -0.26938316226005554, 3232519684096.0, 3232519684096.0, 0.2928888201713562, -0.2190600037574768, -0.45917096734046936, 0.4543541669845581, 0.6723352670669556, 0.42371368408203125, 0.7025423049926758, -0.5277975797653198, 0.20651116967201233, 0.9564807415008545, 0.5807961225509644, -0.09085062146186829, 0.8281147480010986, 0.28297609090805054, -0.3312400281429291, -0.267162948846817]\n"
     ]
    }
   ],
   "source": [
    "print (wrong_line)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76612ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 208, 71]\n"
     ]
    }
   ],
   "source": [
    "result_final = []\n",
    "result_cnt = [0,0,0]\n",
    "for x in result:\n",
    "  if x <= -0.7875 : \n",
    "    result_cnt[0] += 1\n",
    "    result_final.append(0) \n",
    "  elif x >= 0.540 : \n",
    "    result_cnt[2] += 1\n",
    "    result_final.append(2)\n",
    "  else : \n",
    "    result_cnt[1] += 1\n",
    "    result_final.append(1)\n",
    "\n",
    "print(result_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cf38e-2062-4645-9095-2ebac375711e",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b00cd-5680-4bf2-b7f8-0bea6ae8299e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Y_Class'] = result_final\n",
    "submit.to_csv('./idea1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08f836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8392b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec916af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819dfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1eecef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901fe182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f60ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35259477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0f776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc4d55d52d1114a871817dc9d2b4e4d90b6d108a695844ce0d6cbea98b4fea22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
